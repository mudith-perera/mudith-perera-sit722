name: PROD - Deploy to AKS (main branch)

on:
  push:
    branches: [master]
  workflow_dispatch: {}

env:
  AZ_LOCATION: ${{ vars.AZ_LOCATION || 'australiaeast' }}
  PROD_RG: ${{ vars.PROD_RG || 'sit722-prod-rg' }}
  PROD_AKS: ${{ vars.PROD_AKS || 'sit722-prod-aks' }}
  PROD_ACR: ${{ vars.PROD_ACR }}
  K8S_NAMESPACE: ${{ vars.K8S_NAMESPACE || 'app' }}
  IMAGE_TAG: ${{ github.sha }}

jobs:
  prod-deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Ensure RG & ACR
        run: |
          az group create -n $PROD_RG -l $AZ_LOCATION
          if ! az acr show -n $PROD_ACR >/dev/null 2>&1; then
            az acr create -n $PROD_ACR -g $PROD_RG --sku Basic -l $AZ_LOCATION
          fi
          echo "LOGIN_SERVER=$(az acr show -n $PROD_ACR --query loginServer -o tsv)" >> $GITHUB_ENV

      - name: Ensure AKS exists & attach ACR
        run: |
          if ! az aks show -g $PROD_RG -n $PROD_AKS >/dev/null 2>&1; then
            az aks create -g $PROD_RG -n $PROD_AKS -l $AZ_LOCATION \
              --node-count 1 --node-vm-size Standard_B2s \
              --enable-managed-identity --attach-acr $PROD_ACR \
              --generate-ssh-keys
          else
            az aks update -g $PROD_RG -n $PROD_AKS --attach-acr $PROD_ACR || true
          fi
          az aks get-credentials -g $PROD_RG -n $PROD_AKS --overwrite-existing

      # üîê Ensure we can push to ACR
      - name: ACR login (via Azure CLI)
        run: |
          az acr login -n $PROD_ACR

      # (Optional, idempotent) make sure the SP has AcrPush on this registry
      - name: Ensure SP has AcrPush on ACR
        run: |
          APP_ID=$(echo '${{ secrets.AZURE_CREDENTIALS }}' | jq -r '.clientId')
          SCOPE=$(az acr show -n $PROD_ACR --query id -o tsv)
          az role assignment create --assignee "$APP_ID" --role AcrPush --scope "$SCOPE" || true

      # üîπ Build & push all images for this commit
      - name: Build & push product_service
        run: |
          docker build -t $LOGIN_SERVER/product-service:$IMAGE_TAG backend/product_service
          docker push $LOGIN_SERVER/product-service:$IMAGE_TAG

      - name: Build & push order_service
        run: |
          docker build -t $LOGIN_SERVER/order-service:$IMAGE_TAG backend/order_service
          docker push $LOGIN_SERVER/order-service:$IMAGE_TAG

      - name: Build & push customer_service
        run: |
          docker build -t $LOGIN_SERVER/customer-service:$IMAGE_TAG backend/customer_service
          docker push $LOGIN_SERVER/customer-service:$IMAGE_TAG

      - name: Build & push frontend
        run: |
          docker build -t $LOGIN_SERVER/frontend:$IMAGE_TAG frontend
          docker push $LOGIN_SERVER/frontend:$IMAGE_TAG

      - name: Create namespace
        run: kubectl create namespace $K8S_NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

      - name: Apply base manifests for each app
        run: |
          for app in product-service order-service customer-service frontend; do
            sed "s/\$APP_NAME/$app/g; s/\$K8S_NAMESPACE/$K8S_NAMESPACE/g" k8s/deployement.yaml | kubectl apply -f -
            sed "s/\$APP_NAME/$app/g; s/\$K8S_NAMESPACE/$K8S_NAMESPACE/g" k8s/service.yaml     | kubectl apply -f -
          done

      - name: Set images (current commit)
        run: |
          kubectl -n $K8S_NAMESPACE set image deployment/product-service  product-service=$LOGIN_SERVER/product-service:$IMAGE_TAG --record
          kubectl -n $K8S_NAMESPACE set image deployment/order-service    order-service=$LOGIN_SERVER/order-service:$IMAGE_TAG     --record
          kubectl -n $K8S_NAMESPACE set image deployment/customer-service customer-service=$LOGIN_SERVER/customer-service:$IMAGE_TAG --record
          kubectl -n $K8S_NAMESPACE set image deployment/frontend         frontend=$LOGIN_SERVER/frontend:$IMAGE_TAG               --record

      - name: Wait for rollouts
        run: |
          for d in product-service order-service customer-service frontend; do
            kubectl -n $K8S_NAMESPACE rollout status deployment/$d --timeout=300s
          done

      - name: Show frontend external IP
        run: |
          echo "Checking for external IP..."
          for i in {1..20}; do
            echo "Attempt $i/20..."
            
            # Try multiple JSONPath queries to handle different cloud providers
            IP=$(kubectl -n $K8S_NAMESPACE get svc frontend -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
            
            # If ip field is empty, try hostname field (for AWS ELB)
            if [ -z "$IP" ]; then
              IP=$(kubectl -n $K8S_NAMESPACE get svc frontend -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
            fi
            
            # Debug: Show the actual service status
            echo "Service status:"
            kubectl -n $K8S_NAMESPACE get svc frontend -o yaml | grep -A 10 "loadBalancer:"
            
            if [ -n "$IP" ] && [ "$IP" != "<none>" ]; then
              echo "‚úÖ Production External IP found: http://$IP"
              echo "üåê You can access your application at: http://$IP"
              break
            else
              echo "‚è≥ External IP not ready yet, waiting..."
              if [ $i -eq 20 ]; then
                echo "‚ùå Timeout waiting for external IP. Please check manually:"
                echo "   kubectl -n $K8S_NAMESPACE get svc frontend"
              fi
              sleep 15
            fi
          done

          # Show final service status regardless
          echo ""
          echo "Final service status:"
          kubectl -n $K8S_NAMESPACE get svc frontend -o wide
